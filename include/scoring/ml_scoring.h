// Copyright (C) 2024 ETH Zurich.
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
//       notice, this list of conditions and the following disclaimer.
//
//     * Redistributions in binary form must reproduce the above
//       copyright notice, this list of conditions and the following
//       disclaimer in the documentation and/or other materials provided
//       with the distribution.
//
//     * Neither the name of ETH Zurich nor the
//       names of its contributors may be used to endorse or promote products
//       derived from this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.
//
// Please contact the author of this library if you have any questions.
// Author: Daniel Barath (majti89@gmail.com)
#pragma once

#include "../utils/macros.h"
#include "../models/model.h"
#include "../utils/types.h"
#include "../estimators/abstract_estimator.h"
#include "abstract_scoring.h"
#include "score.h"
#include <Eigen/Core>

namespace superansac {
namespace scoring {

class MLScoring : public AbstractScoring
{
    protected: 
        std::vector<double> weights;

    public:
        // Constructor 
        MLScoring() 
        {
            weights = { 1.000000000000000000e+00, 9.996986389160156250e-01, 9.993075728416442871e-01, 9.988622665405273438e-01, 9.976378679275512695e-01, 9.959287643432617188e-01, 9.943858385086059570e-01, 9.914412498474121094e-01, 9.882120490074157715e-01, 9.847329854965209961e-01, 9.812352657318115234e-01, 9.776020646095275879e-01, 9.734677672386169434e-01, 9.696208238601684570e-01, 9.652802944183349609e-01, 9.599336385726928711e-01, 9.550825357437133789e-01, 9.498690366744995117e-01, 9.442762136459350586e-01, 9.385560750961303711e-01, 9.325748682022094727e-01, 9.260593652725219727e-01, 9.202944636344909668e-01, 9.138432741165161133e-01, 9.071764349937438965e-01, 9.003211855888366699e-01, 8.932476639747619629e-01, 8.854508996009826660e-01, 8.772475719451904297e-01, 8.692319393157958984e-01, 8.611050248146057129e-01, 8.528071641921997070e-01, 8.441033959388732910e-01, 8.354468345642089844e-01, 8.261936902999877930e-01, 8.176728487014770508e-01, 8.087983727455139160e-01, 8.002313375473022461e-01, 7.915152907371520996e-01, 7.824071645736694336e-01, 7.730977535247802734e-01, 7.641159892082214355e-01, 7.553073167800903320e-01, 7.460430264472961426e-01, 7.368225455284118652e-01, 7.271680831909179688e-01, 7.180888652801513672e-01, 7.087206840515136719e-01, 6.994091868400573730e-01, 6.897679567337036133e-01, 6.797779202461242676e-01, 6.702997684478759766e-01, 6.606365442276000977e-01, 6.506555676460266113e-01, 6.408702135086059570e-01, 6.312776207923889160e-01, 6.216248273849487305e-01, 6.117135882377624512e-01, 6.022525429725646973e-01, 5.925555229187011719e-01, 5.830375552177429199e-01, 5.734943151473999023e-01, 5.638118982315063477e-01, 5.543307662010192871e-01, 5.450780391693115234e-01, 5.362320542335510254e-01, 5.273249149322509766e-01, 5.184459090232849121e-01, 5.096135735511779785e-01, 5.005189180374145508e-01, 4.913268089294433594e-01, 4.823573231697082520e-01, 4.734397232532501221e-01, 4.643362462520599365e-01, 4.552560150623321533e-01, 4.461644887924194336e-01, 4.369090199470520020e-01, 4.274943768978118896e-01, 4.181098341941833496e-01, 4.087012410163879395e-01, 3.993792831897735596e-01, 3.897454142570495605e-01, 3.797050416469573975e-01, 3.696707487106323242e-01, 3.595604896545410156e-01, 3.494149446487426758e-01, 3.391455113887786865e-01, 3.289115428924560547e-01, 3.186329007148742676e-01, 3.082188665866851807e-01, 2.976641952991485596e-01, 2.868560254573822021e-01, 2.760170102119445801e-01, 2.649995684623718262e-01, 2.538325488567352295e-01, 2.424141764640808105e-01, 2.310465425252914429e-01, 2.194349169731140137e-01, 2.078784704208374023e-01, 1.962653994560241699e-01, 1.848038136959075928e-01, 1.735345125198364258e-01, 1.624266505241394043e-01, 1.515999585390090942e-01, 1.411016434431076050e-01, 1.309769153594970703e-01, 1.212585046887397766e-01, 1.120242699980735779e-01, 1.032072007656097412e-01, 9.492476284503936768e-02, 8.706002682447433472e-02, 7.972534745931625366e-02, 7.290802150964736938e-02, 6.661254912614822388e-02, 6.079822406172752380e-02, 5.546011403203010559e-02, 5.058271065354347229e-02, 4.613763466477394104e-02, 4.209944233298301697e-02, 3.842991217970848083e-02, 3.509717434644699097e-02, 3.207578137516975403e-02, 2.934298664331436157e-02, 2.686768025159835815e-02, 2.462869510054588318e-02, 2.260100096464157104e-02, 2.075893431901931763e-02, 1.909031346440315247e-02, 1.757728308439254761e-02, 1.620446331799030304e-02, 1.495617162436246872e-02, 1.382020115852355957e-02, 1.278676185756921768e-02, 1.184458006173372269e-02, 1.098548527806997299e-02, 1.020033191889524460e-02, 9.482717141509056091e-03, 8.825782686471939087e-03, 8.224313147366046906e-03, 7.672316394746303558e-03, 7.164948154240846634e-03, 6.698649842292070389e-03, 6.269450299441814423e-03, 5.873899906873703003e-03, 5.508806556463241577e-03, 5.171591416001319885e-03, 4.859488923102617264e-03, 4.570601042360067368e-03, 4.302913788706064224e-03, 4.054441582411527634e-03, 3.823657752946019173e-03, 3.609025850892066956e-03, 3.409243887290358543e-03, 3.223072038963437080e-03, 3.049354767426848412e-03, 2.887074137106537819e-03, 2.735413145273923874e-03, 2.593482378870248795e-03, 2.460607560351490974e-03, 2.336073899641633034e-03, 2.219268120825290680e-03, 2.109619555994868279e-03, 2.006612718105316162e-03, 1.909750280901789665e-03, 1.818595919758081436e-03, 1.732734846882522106e-03, 1.651814207434654236e-03, 1.575490692630410194e-03, 1.503455103375017643e-03, 1.435409882105886936e-03, 1.371093094348907471e-03, 1.310270046815276146e-03, 1.252710120752453804e-03, 1.198196667246520519e-03, 1.146540511399507523e-03, 1.097567379474639893e-03, 1.051108120009303093e-03, 1.007004291750490665e-03, 9.651196887716650963e-04, 9.253199095837771893e-04, 8.874844643287360668e-04, 8.514975197613239288e-04, 8.172511588782072067e-04, 7.846466614864766598e-04, 7.535879849456250668e-04, 7.239886326715350151e-04, 6.957676378078758717e-04, 6.688503781333565712e-04, 6.431629299186170101e-04, 6.186398677527904510e-04, 5.952168139629065990e-04, 5.728387623094022274e-04, 5.514499498531222343e-04, 5.309988046064972878e-04, 5.114368977956473827e-04, 4.927194677293300629e-04, 4.748034989461302757e-04, 4.576496139634400606e-04, 4.412193375173956156e-04, 4.254770465195178986e-04, 4.103886603843420744e-04, 3.959227760788053274e-04, 3.820486308541148901e-04, 3.687374701257795095e-04, 3.559641190804541111e-04, 3.437025879975408316e-04, 3.319299430586397648e-04, 3.206227847840636969e-04, 3.097599255852401257e-04, 2.993213129229843616e-04, 2.892879710998386145e-04, 2.796414482872933149e-04, 2.703644277062267065e-04, 2.614402619656175375e-04, 2.528538170736283064e-04, 2.445905411150306463e-04, 2.366363187320530415e-04, 2.289778785780072212e-04, 2.216027205577120185e-04, 2.144986647181212902e-04, 2.076543605653569102e-04, 2.010587195400148630e-04, 1.947014243341982365e-04, 1.885726669570431113e-04, 1.826628868002444506e-04, 1.769633090589195490e-04, 1.714653626549988985e-04, 1.661607675487175584e-04, 1.610420149518176913e-04, 1.561017852509394288e-04, 1.513329043518751860e-04, 1.467285474063828588e-04, 1.422822388121858239e-04, 1.379879249725490808e-04, 1.338397560175508261e-04, 1.298319402849301696e-04, 1.259591372217983007e-04, 1.222161954501643777e-04, 1.185981964226812124e-04, 1.151004544226452708e-04, 1.117183637688867748e-04, 1.084477262338623405e-04, 1.052843363140709698e-04, 1.022243377519771457e-04, 9.926390339387580752e-05, 9.639942436479032040e-05, 9.362734999740496278e-05, 9.094433335121721029e-05, 8.834715845296159387e-05, 8.583271846873685718e-05, 8.339805208379402757e-05, 8.104035805445164442e-05, 7.875689334468916059e-05, 7.654500950593501329e-05, 7.440224726451560855e-05, 7.232617645058780909e-05, 7.031443965388461947e-05, 6.836485408712178469e-05, 6.647529517067596316e-05, 6.464368198066949844e-05, 6.286799907684326172e-05, 6.114636198617517948e-05, 5.947692625341005623e-05, 5.785794564872048795e-05, 5.628773214993998408e-05, 5.476466321852058172e-05, 5.328713450580835342e-05, 5.185366899240761995e-05, 5.046281148679554462e-05, 4.911313953925855458e-05, 4.780329618370160460e-05, 4.653197538573294878e-05, 4.529795842245221138e-05, 4.410001201904378831e-05, 4.293696110835298896e-05, 4.180768883088603616e-05, 4.071111106895841658e-05, 3.964615825680084527e-05, 3.861184086417779326e-05, 3.760718755074776709e-05, 3.663124516606330872e-05, 3.568312604329548776e-05, 3.476196434348821640e-05, 3.386688331374898553e-05, 3.299708259874023497e-05, 3.215177275706082582e-05, 3.133020072709769011e-05, 3.053162799915298820e-05, 2.975534698634874076e-05, 2.900067192967981100e-05, 2.826694253599271178e-05, 2.755352761596441269e-05, 2.685980507521890104e-05, 2.618518556118942797e-05, 2.552908154029864818e-05, 2.489093822077848017e-05, 2.427021900075487792e-05, 2.366640183026902378e-05, 2.307897921127732843e-05, 2.250746365461964160e-05, 2.195138222305104136e-05, 2.141028562618885189e-05, 2.088372639263980091e-05, 2.037127342191524804e-05, 1.987251926038879901e-05, 1.938706373039167374e-05, 1.891452302515972406e-05, 1.845452061388641596e-05, 1.800668906071223319e-05, 1.757068275765050203e-05, 1.714615427772514522e-05, 1.673277256486471742e-05, 1.633021929592359811e-05, 1.593818706169258803e-05, 1.555637936689890921e-05, 1.518449880677508190e-05, 1.482227162341587245e-05, 1.446941951144253835e-05, 1.412568235537037253e-05, 1.379080094920936972e-05, 1.346452791040064767e-05, 1.314662131335353479e-05, 1.283684650843497366e-05, 1.253498157893773168e-05, 1.224080369865987450e-05, 1.195410186483059078e-05, 1.167466598417377099e-05, 1.140229778684442863e-05, 1.113680355047108606e-05, 1.087799591914517805e-05, 1.062569390342105180e-05, 1.037972015183186159e-05, 1.013990004139486700e-05, 9.906068044074345380e-06, 9.678060450823977590e-06, 9.455719919060356915e-06, 9.238895472662989050e-06, 9.027438863995485008e-06, 8.821204573905561119e-06, 8.620054359198547900e-06, 8.423852705163881183e-06, 8.232468644564505666e-06, 8.045773938647471368e-06, 7.863643077143933624e-06, 7.685956916247960180e-06, 7.512595402658917010e-06, 7.343448032770538703e-06, 7.178402029239805415e-06, 7.017350526439258829e-06, 6.860188932478195056e-06, 6.706815383950015530e-06, 6.557131655426928774e-06, 6.411042704712599516e-06, 6.268454853852745146e-06, 6.129277153377188370e-06, 5.993422746541909873e-06, 5.860805231350241229e-06, 5.731340479542268440e-06, 5.604949365078937262e-06, 5.481552307173842564e-06, 5.361073363019386306e-06, 5.243437954050023109e-06, 5.128573775436962023e-06, 5.016410341340815648e-06, 4.906879439658951014e-06, 4.799914677278138697e-06, 4.695451934821903706e-06, 4.593427547661121935e-06, 4.493781034398125485e-06, 4.396451458887895569e-06, 4.301381977711571380e-06, 4.208516656944993883e-06, 4.117799107916653156e-06, 4.029176579933846369e-06, 3.942597231798572466e-06, 3.858010586554883048e-06, 3.775366849367856048e-06, 3.694618044391972944e-06, 3.615717787397443317e-06, 3.538621513143880293e-06, 3.463283974269870669e-06, 3.389662424524431117e-06, 3.317714799777604640e-06, 3.247400627515162341e-06, 3.178679662596550770e-06, 3.111514388365321793e-06, 3.045865241801948287e-06, 2.981696525239385664e-06, 2.918972086263238452e-06, 2.857657591448514722e-06, 2.797718934743897989e-06, 2.739122919592773542e-06, 2.681837258933228441e-06, 2.625831257319077849e-06, 2.571073537183110602e-06, 2.517534767321194522e-06, 2.465185843902872875e-06, 2.413998572592390701e-06, 2.363945213801343925e-06, 2.314998937436030246e-06, 2.267133140776422806e-06, 2.220322585344547406e-06, 2.174542260036105290e-06, 2.129768290615174919e-06, 2.085976575472159311e-06, 2.043144377239514142e-06, 2.001249185923370533e-06, 1.960269173650885932e-06, 1.920182739922893234e-06, 1.880968966361251660e-06, 1.842607730395684484e-06, 1.805079364203265868e-06, 1.768364427334745415e-06, 1.732444502522412222e-06, 1.697300945124879945e-06, 1.662916019995464012e-06, 1.629271878300642129e-06, 1.596351694388431497e-06, 1.564138983667362481e-06, 1.532617602606478613e-06, 1.501771407674823422e-06, 1.471585051149304491e-06, 1.442043640054180287e-06, 1.413132281413709279e-06, 1.384836991746851709e-06, 1.357143673885730095e-06, 1.330038458036142401e-06, 1.303508497585426085e-06, 1.277540377486729994e-06, 1.252121592187904753e-06, 1.227239749823638704e-06, 1.202882685902295634e-06, 1.179038918053265661e-06, 1.155696622845425736e-06, 1.132844658968679141e-06, 1.110471998799766880e-06, 1.088567955775943119e-06, 1.067122070708137471e-06, 1.046124452841468155e-06, 1.025564870360540226e-06, 1.005433773570985068e-06, 9.857214990915963426e-07, 9.664189519753563218e-07, 9.475169235884095542e-07, 9.290067168876703363e-07, 9.108795779866341036e-07, 8.931269235290528741e-07, 8.757408522797049955e-07, 8.587133493165310938e-07, 8.420364565608906560e-07, 8.257025001512374729e-07, 8.097039199128630571e-07, 7.940334967315720860e-07, 7.786841251800069585e-07, 7.636486998308100738e-07, 7.489204563171369955e-07, 7.344928008023998700e-07, 7.203592531368485652e-07, 7.065133900141518097e-07, 6.929490155016537756e-07, 6.796599905101174954e-07, 6.666405738542380277e-07, 6.538847401316161267e-07, 6.413869755306222942e-07, 6.291417662396270316e-07, 6.171436552904197015e-07, 6.053874130884651095e-07, 5.938677531958092004e-07, 5.825797302350110840e-07, 5.715183988286298700e-07, 5.606788135992246680e-07, 5.500564270732866134e-07, 5.396465780904691201e-07, 5.294447760206821840e-07, 5.194466439206735231e-07, 5.096479753774474375e-07, 5.000444502911705058e-07, 4.906320327791036107e-07, 4.814067438019264955e-07, 4.723644622117717518e-07, 4.635013794995757053e-07, 4.548138008431124035e-07, 4.462981451069936156e-07, 4.379508311558311107e-07, 4.297683062759460881e-07, 4.217470177536597475e-07, 4.138838676226441748e-07, 4.061755873863148736e-07, 3.986189085480873473e-07, 3.912108184067619732e-07, 3.839483326828485588e-07, 3.768284386751474813e-07, 3.698482373692968395e-07, 3.630050002811913146e-07, 3.562961978786916006e-07, 3.497193006296583917e-07, 3.432721484841749771e-07, 3.369529792962566717e-07, 3.307607130409451202e-07, 3.246968560688401340e-07 };
        }

        // Destructor
        ~MLScoring() {}

        // Set the threshold
        FORCE_INLINE void setThreshold(const double kThreshold_)
        {
            threshold = kThreshold_;
            squaredThreshold = threshold * threshold;
        }

        // Sample function
        FORCE_INLINE Score score(
            const DataMatrix &kData_, // Data matrix
            const models::Model &kModel_, // The model to be scored
            const estimator::Estimator *kEstimator_, // Estimator
            std::vector<size_t> &inliers_, // Inlier indices
            const bool kStoreInliers_ = true,
            const Score& kBestScore_ = Score(),
            std::vector<const std::vector<size_t>*> *kPotentialInlierSets_ = nullptr) const // The potential inlier sets from the inlier selector
        {   
            // Create a static empty Score
            static const Score kEmptyScore;
            // The number of points
            const int kPointNumber = kData_.rows();
            // The squared residual
            double squaredResidual;
            // Score and inlier number
            int inlierNumber = 0;
            double scoreValue = 0.0;
            // The score of the previous best model
            const double kBestInlierNumber = kBestScore_.getInlierNumber();

            const size_t kHistogramSize = 500;
            const double kBinSize = squaredThreshold / static_cast<double>(kHistogramSize * kHistogramSize);

            std::vector<size_t> histogram(kHistogramSize, 0);

            // Iterate through all points, calculate the squaredResiduals and store the points as inliers if needed.
            for (int pointIdx = 0; pointIdx < kPointNumber; ++pointIdx)
            {
                // Calculate the point-to-model residual
                squaredResidual =
                    kEstimator_->squaredResidual(kData_.row(pointIdx),
                        kModel_);

                // If the residual is smaller than the threshold, store it as an inlier and
                // increase the score.
                if (squaredResidual < squaredThreshold)
                {
                    if (kStoreInliers_) // Store the point as an inlier if needed.
                        inliers_.emplace_back(pointIdx);

                    // Increase the inlier number
                    ++inlierNumber;
                    
                    int index = static_cast<int>(std::ceil(squaredResidual / kBinSize)); //std::min(std::max(static_cast<size_t>(std::ceil(squaredResidual / kBinSize)) - 1, 0), kHistogramSize - 1);
                    if (index >= kHistogramSize)
                        index = kHistogramSize - 1;
                    else if (index < 0)
                        index = 0;
                    ++histogram[index];
                }

                // Interrupt if there is no chance of being better than the best model
                if (kPointNumber - pointIdx + inlierNumber < kBestInlierNumber)
                    return kEmptyScore;
            }

            for (size_t bin = 0; bin < kHistogramSize; ++bin)
                scoreValue += weights[bin] * histogram[bin];

            return Score(inlierNumber, scoreValue);
        }

        // Get weights for the points
        FORCE_INLINE void getWeights(
            const DataMatrix &kData_, // Data matrix
            const models::Model &kModel_, // The model to be scored
            const estimator::Estimator *kEstimator_, // Estimator
            std::vector<double> &weights_, // The weights of the points
            const std::vector<size_t> *kIndices_ = nullptr) const  // The indices of the points
        {
            if (kIndices_ == nullptr)
            {
                // The number of points
                const int kPointNumber = kData_.rows();
                // The squared residual
                double squaredResidual;
                // Allocate memory for the weights
                weights_.resize(kPointNumber);

                // Iterate through all points, calculate the squaredResiduals and store the points as inliers if needed.
                for (int pointIdx = 0; pointIdx < kPointNumber; ++pointIdx)
                {
                    // Calculate the point-to-model residual
                    squaredResidual =
                        kEstimator_->squaredResidual(kData_.row(pointIdx),
                            kModel_);

                    // If the residual is smaller than the threshold, store it as an inlier and
                    // increase the score.
                    if (squaredResidual < squaredThreshold)
                        weights_[pointIdx] = log(1.0 + exp((squaredThreshold - squaredResidual) / (2.0 * squaredThreshold)));
                    else
                        weights_[pointIdx] = 0.0;
                }
            }
            else
            {
                // The number of points
                const int kPointNumber = kIndices_->size();
                // The squared residual
                double squaredResidual;
                // Allocate memory for the weights
                weights_.resize(kPointNumber);

                // Iterate through all points, calculate the squaredResiduals and store the points as inliers if needed.
                for (int pointIdx = 0; pointIdx < kPointNumber; ++pointIdx)
                {
                    // Calculate the point-to-model residual
                    squaredResidual =
                        kEstimator_->squaredResidual(kData_.row((*kIndices_)[pointIdx]),
                            kModel_);

                    // If the residual is smaller than the threshold, store it as an inlier and
                    // increase the score.
                    if (squaredResidual < squaredThreshold)
                        weights_[pointIdx] = log(1.0 + exp((squaredThreshold - squaredResidual) / (2.0 * squaredThreshold)));
                    else
                        weights_[pointIdx] = 0.0;
                }
            }
        }
};

}
}